\sectioncentered*{Заключение}
\addcontentsline{toc}{section}{Заключение}

В данной работе были проведены исследования в области языкового моделирования для домена белорусского языка. С использованием множества библиотек языка Python были реализованы предобработка данных, архитектуры нейросетевых моделей, процесс обучения, логирования результатов и расчета метрик. Далее был произведен анализ результатов для определения оптимальной архитектуры языковой модели для белорусского языка.

Были рассмотрены следующие ахитектуры: Kneser-Nay, LSTM и Transformer. Kneser-Nay использовался в качестве бейзлайна и позволил оценить, к какому результату можно стремиться для других моделей. Для архитектуры LSTM была проведена основная исследовательская работа, были рассмотрены различные комбинации параметров модели и получено хорошее итоговое качество. Трансформеры рассматривались как перспективное направление исследований при наличии большего набора данных. Была обучена уменьшенная версия модели gpt-2, для которой также удалось достичь неплохих результатов.

В результате цель дипломной работы была достигнута. Были созданы языковые модели, которые дают хорошее качество и могут применяться в различных приложениях. Стоит отметить, что данный результат можно значительно улучшить. В дальнейшем планируется провести дополнительные исследования по выбору оптимальной архитектуры, в особенности с использованием трансформеров, а также найти в несколько раз больше данных, что может позволить создать для белорусского языка модель, которая не будет уступать аналогам для более распространенных языков.
