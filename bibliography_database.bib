% This file was created with JabRef 2.9.2.
% Encoding: utf8

@MISC{ibm_nlp,
	title = {Natural Language Processing (NLP)},
	howpublished = {Электронные данные},
	note = {Режим доступа: \url{https://www.ibm.com/cloud/learn/natural-language-processing}. --- Дата
	доступа: 16.04.2022},
	owner = {dinohunter2836},
	timestamp = {2022.04.16}
}

@MISC{lm_definition,
	title = {Natural Language Processing (NLP)},
	howpublished = {Электронные данные},
	note = {Режим доступа: \url{https://www.techtarget.com/searchenterpriseai/definition/language-modeling}. --- Дата
	доступа: 16.04.2022},
	owner = {dinohunter2836},
	timestamp = {2022.04.16}
}

@ARTICLE{mt_first,
	title = {A Statistical Approach to Machine Translation},
	author = {Brown, Peter F. and Cocke, John  and Della Pietra, Stephen A. and Della Pietra, Vincent J. and
	Jelinek, Fredrick and Lafferty, John D.  and
	Mercer, Robert L. and Roossin, Paul S.},
	journal = {Computational Linguistics},
	volume = {16},
	number = {2},
	year = {1990},
	url = {https://aclanthology.org/J90-2002},
	pages = {79--85},
}

@ARTICLE{shannon-math-theory-of-communication,
	title = {A Mathematical Theory of Communication},
	author = {C. E. Shannon},
	journal = {Bell System Technical Journal},
	volume = {55},
	number = {1},
	year = {1948},
	url = {https://people.math.harvard.edu/~ctm/home/text/others/shannon/entropy/entropy.pdf},
}

@MISC{backprop_first_mention,
	title = {Who Invented Backpropagation},
	howpublished = {Электронные данные},
	note = {Режим доступа: \url{https://people.idsia.ch/~juergen/who-invented-backpropagation.html}. --- Дата
	доступа: 17.04.2022},
	owner = {dinohunter2836},
	timestamp = {2022.04.17}
}

@MISC{language_modeling_abstract,
	title = {Language Modeling},
	howpublished = {Электронные данные},
	note = {Режим доступа: \url{https://www.techtarget.com/searchenterpriseai/definition/language-modeling}. --- Дата
	доступа: 17.04.2022},
	owner = {dinohunter2836},
	timestamp = {2022.04.17}
}

@ARTICLE{shannon-math-theory-of-communication,
	title = {A Mathematical Theory of Communication},
	author = {Claude E. Shannon},
	journal = {Bell System Technical Journal},
	volume = {27},
	year = {1948},
	url = {https://people.math.harvard.edu/~ctm/home/text/others/shannon/entropy/entropy.pdf},
}

@ARTICLE{hopfield_rnn,
	title = {Neural networks and physical systems with emergent collective computational abilities},
	author = {John J. Hopfield},
	journal = {National Academy of Sciences, USA},
	volume = {79},
	number = {8},
	year = {1982},
	url = {https://www.pnas.org/doi/epdf/10.1073/pnas.79.8.2554},
}

@ARTICLE{rumelhart_backprop,
	title = {Learning representations by back-propagating errors},
	author = {Rumelhart D., Hinton G., Williams R.},
	journal = {Nature},
	volume = {323},
	year = {1986},
	url = {https://web.stanford.edu/class/psych209a/ReadingsByDate/02_06/PDPVolIChapter8.pdf},
}

@ARTICLE{kneser_ney,
	title = {Improved backing-off for M-gram language modeling},
	author = {Reinhard Kneser, H. Ney},
	journal = {1995 International Conference on Acoustics, Speech, and Signal Processing},
	volume = {6},
	year = {1995},
	url = {https://www-i6.informatik.rwth-aachen.de/publications/download/951/Kneser-ICASSP-1995.pdf},
	pages = {181--184},
}

@ARTICLE{lstm,
	title = {LONG SHORT-TERM MEMORY},
	author = {Sepp Hochreiter, Jurgen Schmidhuber},
	journal = {Neural Comput 1997},
	volume = {9},
	number = {8},
	year = {1995},
	url = {https://www-i6.informatik.rwth-aachen.de/publications/download/951/Kneser-ICASSP-1995.pdf},
	pages = {1735--1780},
}

@ARTICLE{first_neural_lm,
	title = {A Neural Probabilistic Language Model},
	author = {Yoshua Bengio, Rejean Ducharme, Pascal Vincent, Christian Jauvin},
	journal = {Journal of Machine Learning Research},
	volume = {3},
	year = {2003},
	url = {https://www.jmlr.org/papers/volume3/bengio03a/bengio03a.pdf},
	pages = {1137--1155},
}

@ARTICLE{word2vec,
	author = {Mikolov, Tomas and Chen, Kai and Corrado, G.s and Dean, Jeffrey},
	year = {2013},
	month = {01},
	pages = {},
	title = {Efficient Estimation of Word Representations in Vector Space},
	volume = {2013},
	journal = {Proceedings of Workshop at ICLR}
}

@inproceedings{pennington-etal-2014-glove,
	title = {GloVe: Global Vectors for Word Representation},
	author = {Pennington, Jeffrey  and
	Socher, Richard  and
	Manning, Christopher},
	booktitle = {Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing ({EMNLP})},
	month = {oct},
	year = {2014},
	address = {Doha, Qatar},
	publisher = {Association for Computational Linguistics},
	url = {https://aclanthology.org/D14-1162},
	pages = {1532--1543},
}

@inproceedings{kalchbrenner-etal-2014-convolutional,
	title = {A Convolutional Neural Network for Modelling Sentences},
	author = {Kalchbrenner, Nal  and
	Grefenstette, Edward  and
	Blunsom, Phil},
	booktitle = {Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
	month = {jun},
	year = {2014},
	address = {Baltimore, Maryland},
	publisher = {Association for Computational Linguistics},
	url = {https://aclanthology.org/P14-1062},
	doi = {10.3115/v1/P14-1062},
	pages = {655--665},
}

@article{sutskever2013training,
	added-at = {2018-05-22T00:12:48.000+0200},
	author = {Sutskever, Ilya},
	biburl = {https://www.bibsonomy.org/bibtex/20206a37e46da7a3c3e6a30cab839e6fb/dallmann},
	description = {scholar.googleusercontent.com/scholar.bib?q=info:LKn-6XMpQaAJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWwNGZ4Djj6gcJjdwauFg4drsvHEWsMfD&scisf=4&ct=citation&cd=-1&hl=en},
	interhash = {43074181bc20f9d8c1c5a97b29b73fb8},
	intrahash = {0206a37e46da7a3c3e6a30cab839e6fb},
	journal = {University of Toronto, Toronto, Ont., Canada},
	keywords = {deep_learning mlnlp phd rnn thesis},
	timestamp = {2018-05-22T00:12:48.000+0200},
	title = {Training recurrent neural networks},
	url = {http://www.cs.utoronto.ca/~ilya/pubs/ilya_sutskever_phd_thesis.pdf},
	year = {2013}
}

@MISC{neural-lm-history,
	title = {A Review of the Neural History of Natural Language Processing},
	author = {Ruder, Sebastian},
	howpublished = {Электронные данные},
	note = {Режим доступа: \url{https://ruder.io/a-review-of-the-recent-history-of-nlp/}. --- Дата
	доступа: 17.04.2022},
	owner = {dinohunter2836},
	timestamp = {2022.04.17}
}

@MISC{twds-lm-history,
	title = {Evolution of Language Models: N-Grams, Word Embeddings, Attention and Transformers},
	howpublished = {Электронные данные},
	note = {Режим доступа: \url{https://towardsdatascience.com/evolution-of-language-models-n-grams-word-embeddings-attention-transformers-a688151825d2}. --- Дата
	доступа: 17.04.2022},
	owner = {dinohunter2836},
	timestamp = {2022.04.17}
}

@MISC{lena-voita-lm,
	title = {Lena Voita - NLP Course For You | Language Modeling},
	howpublished = {Электронные данные},
	note = {Режим доступа: \url{https://lena-voita.github.io/nlp_course/language_modeling.html}. --- Дата
	доступа: 17.04.2022},
	owner = {dinohunter2836},
	timestamp = {2022.04.17}
}

@MISC{image-captioning,
	doi = {10.48550/ARXIV.1411.4555},
	url = {https://arxiv.org/abs/1411.4555},
	author = {Vinyals, Oriol and Toshev, Alexander and Bengio, Samy and Erhan, Dumitru},
	keywords = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
	title = {Show and Tell: A Neural Image Caption Generator},
	publisher = {arXiv},
	year = {2014},
}

@MISC{attention,
	doi = {10.48550/ARXIV.1409.0473},
	url = {https://arxiv.org/abs/1409.0473},
	author = {Bahdanau, Dzmitry and Cho, Kyunghyun and Bengio, Yoshua},
	keywords = {Computation and Language (cs.CL), Machine Learning (cs.LG), Neural and Evolutionary Computing (cs.NE), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
	title = {Neural Machine Translation by Jointly Learning to Align and Translate},
	publisher = {arXiv},
	year = {2014},
	copyright = {arXiv.org perpetual, non-exclusive license}
}

@MISC{attention-is-all-you-need,
	doi = {10.48550/ARXIV.1706.03762},
	url = {https://arxiv.org/abs/1706.03762},
	author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, Lukasz and Polosukhin, Illia},
	keywords = {Computation and Language (cs.CL), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
	title = {Attention Is All You Need},
	publisher = {arXiv},
	year = {2017},
	copyright = {arXiv.org perpetual, non-exclusive license}
}

@ARTICLE{n_grams,
	author = {Daniel Jurafsky and James H. Martin.},
	howpublished = {Электронные данные},
	year = {2021},
	month = {12},
	title = {N-gram Language Models},
	note = {Режим доступа: \url{https://web.stanford.edu/~jurafsky/slp3/3.pdf}. --- Дата
	доступа: 02.05.2022},
}

@ARTICLE{modified-kneser-ney,
	author = {Chen, Stanley F. and Joshua Goodman},
	publisher = {Harvard Computer Science Group Technical Report},
	year = {1998},
	month = {12},
	title = {An Empirical Study of Smoothing Techniques for Language Modeling},
	pages = {10--98}
}

@MISC{neural_lms,
	title = {Neural Language Models},
	howpublished = {Электронные данные},
	note = {Режим доступа: \url{https://towardsdatascience.com/neural-language-models-32bec14d01dc}. --- Дата
	доступа: 07.05.2022},
	owner = {dinohunter2836},
	timestamp = {2022.05.07}
}

@MISC{lstm_pic,
	title = {LSTM Recurrent Neural Networks — How to Teach a Network to Remember the Past},
	howpublished = {Электронные данные},
	note = {Режим доступа: \url{https://towardsdatascience.com/lstm-recurrent-neural-networks-55e54c2ff22e}. --- Дата
	доступа: 08.05.2022},
	owner = {dinohunter2836},
	timestamp = {2022.05.08}
}

@misc{conv_lm_paper,
	doi = {10.48550/ARXIV.1612.08083},
	url = {https://arxiv.org/abs/1612.08083},
	author = {Dauphin, Yann N. and Fan, Angela and Auli, Michael and Grangier, David},
	keywords = {Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
	title = {Language Modeling with Gated Convolutional Networks},
	publisher = {arXiv},
	year = {2016},
	copyright = {arXiv.org perpetual, non-exclusive license}
}

@MISC{python_for_ml,
	title = {Why Use Python for AI and Machine Learning?},
	howpublished = {Электронные данные},
	note = {Режим доступа: \url{https://steelkiwi.com/blog/python-for-ai-and-machine-learning/}. --- Дата
	доступа: 17.04.2022},
	timestamp = {2022.04.17}
}

@MISC{jupyter,
	title = {Why Use Python for AI and Machine Learning?},
	howpublished = {Электронные данные},
	note = {Режим доступа: \url{https://ipython.readthedocs.io/en/stable/interactive/magics.html}. --- Дата
	доступа: 27.04.2022},
	timestamp = {2022.04.27}
}

@MISC{pytorch_github,
	title = {PyTorch},
	howpublished = {Электронные данные},
	note = {Режим доступа: \url{https://github.com/pytorch/pytorch#a-gpu-ready-tensor-library}. --- Дата
	доступа: 29.04.2022},
	timestamp = {2022.04.29}
}

@MISC{lightning_github,
	title = {PyTorch Lightning},
	howpublished = {Электронные данные},
	note = {Режим доступа: \url{https://github.com/PyTorchLightning/pytorch-lightning}. --- Дата
	доступа: 29.04.2022},
	timestamp = {2022.04.29}
}

@misc{bpe,
	doi = {10.48550/ARXIV.1508.07909},
	url = {https://arxiv.org/abs/1508.07909},
	author = {Sennrich, Rico and Haddow, Barry and Birch, Alexandra},
	keywords = {Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
	title = {Neural Machine Translation of Rare Words with Subword Units},
	publisher = {arXiv},
	year = {2015},
	copyright = {Creative Commons Attribution 4.0 International}
}

@MISC{beam_search,
	title = {Beam Search Algorithm},
	howpublished = {Электронные данные},
	note = {Режим доступа: \url{https://www.baeldung.com/cs/beam-search}. --- Дата
	доступа: 30.04.2022},
	timestamp = {2022.04.30}
}

@MISC{perplexity,
	title = {Perplexity in Language Models},
	howpublished = {Электронные данные},
	note = {Режим доступа: \url{https://towardsdatascience.com/perplexity-in-language-models-87a196019a94}. --- Дата
	доступа: 30.04.2022},
	timestamp = {2022.04.30}
}

@article{gpt2,
	author    = {Xianrui Zheng and
	Chao Zhang and
	Philip C. Woodland},
	title     = {Adapting GPT, {GPT-2} and {BERT} Language Models for Speech Recognition},
	journal   = {CoRR},
	volume    = {abs/2108.07789},
	year      = {2021},
	url       = {https://arxiv.org/abs/2108.07789},
	eprinttype = {arXiv},
	eprint    = {2108.07789},
	timestamp = {Thu, 02 Sep 2021 10:56:26 +0200},
	biburl    = {https://dblp.org/rec/journals/corr/abs-2108-07789.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}

@MISC{cloud_pricing,
	title = {Cloud Natural Language pricing},
	howpublished = {Электронные данные},
	note = {Режим доступа: \url{https://cloud.google.com/natural-language/pricing}. --- Дата
	доступа: 15.04.2022},
	timestamp = {2022.04.15}
}


